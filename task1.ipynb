{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023df9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python-headless\n",
    "!pip install networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a21a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Softmax,Input,MaxPooling2D,Dropout,Dense,Conv2D,Flatten,BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd5355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(os.listdir ('images'))\n",
    "def load_img(f):\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab = [], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "        \n",
    "        im1=cv2.imread(fn)\n",
    "        im1=cv2.resize(im1, (128,128))\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "        \n",
    "    imgs= np.asarray(imgs, np.float32)\n",
    "    lab= np.asarray(lab, np.int32)\n",
    "    return imgs, np.eye(len_y)[lab]\n",
    "\n",
    "x,y = load_img('train.txt')\n",
    "vx,vy = load_img('val.txt')\n",
    "tx,ty = load_img('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51748f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVectorLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, seed=None):\n",
    "        super(RandomVectorLayer, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.generator = tf.random.Generator.from_seed(seed)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        random_vector = self.generator.normal(shape=(tf.shape(inputs)[0],self.output_dim))\n",
    "        random_vector = tf.where(random_vector < 0, 0.0, 1.0)\n",
    "        column_sums = tf.reduce_sum(random_vector, axis=1)\n",
    "        all_zeros_columns = tf.where(column_sums == 0)\n",
    "        for col_index in all_zeros_columns:\n",
    "            index = int(col_index[0])\n",
    "            ones_column = tf.ones_like(random_vector[index, :])\n",
    "            random_vector = tf.tensor_scatter_nd_update(random_vector, [[index]], [ones_column])\n",
    "        x21 = tf.expand_dims(random_vector, axis=1)\n",
    "        x22 = tf.expand_dims(x21, axis=1)\n",
    "        return x22*inputs , random_vector\n",
    "class Dynamic2D(tf.keras.Model):\n",
    "    def __init__(self, K):\n",
    "        super(Dynamic2D, self).__init__()\n",
    "        self.fc1 = Dense(100, use_bias=True)\n",
    "        self.fc2 = Dense(K, use_bias=True)\n",
    "        self.fc3 = Conv2D(K, (3, 3), activation='relu', padding='same')\n",
    "\n",
    "    def call(self, x, r):\n",
    "        r = self.fc1(r)\n",
    "        r = tf.nn.relu(r)\n",
    "        r = self.fc2(r)\n",
    "        r = tf.expand_dims(tf.expand_dims(tf.keras.layers.Softmax()(r), axis=1), axis=1)\n",
    "        x = self.fc3(x)\n",
    "        x = tf.math.multiply(x,r)\n",
    "        return x\n",
    "\n",
    "def net(first_kernel = 64,first_flat = 1024,dynamic=True):\n",
    "    input_x = Input(shape=(128,128,3))\n",
    "    x,r = RandomVectorLayer(output_dim=3, seed=42)(input_x)\n",
    "    if(dynamic):\n",
    "        x = Dynamic2D(K=first_kernel)(x,r)\n",
    "    else:\n",
    "        x = Conv2D(first_kernel, (3, 3), activation='relu', padding='same')(input_x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(first_kernel*2, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x1 = Conv2D(first_kernel*2, (3, 3), activation='relu', padding='same')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x = x + x1\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(first_kernel*4, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x1 = Conv2D(first_kernel*4, (3, 3), activation='relu', padding='same')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x = x + x1\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(first_kernel*8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x1 = Conv2D(first_kernel*8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x = x + x1\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(first_kernel*16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x1 = Conv2D(first_kernel*16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x = x + x1\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(first_flat, activation='relu')(x)\n",
    "    x = Dense(first_flat/4, activation='relu')(x)\n",
    "    x = Dense(len_y, activation='softmax')(x)\n",
    "    model = Model(inputs=input_x, outputs=x)\n",
    "    return model\n",
    "model = net(first_kernel = 64,first_flat = 1024,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,tx,ty,mask,print_stuff = \"\"):\n",
    "    sum_predict = 0\n",
    "    for i in range(len(tx)):\n",
    "        input_x = np.array([[[mask]]])*tx[i:i+1]\n",
    "        y_ = model([input_x,np.array([mask])],training = False)\n",
    "        if(np.argmax(y_[0]) == np.argmax(ty[i])):\n",
    "            sum_predict += 1\n",
    "    print(print_stuff,round(sum_predict/len(tx),4),sum_predict,len(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8dba6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model, model_inputs) -> float:\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + list(inp.shape[1:]), inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops / 1e9)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51112f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(first_kernel = 64,first_flat = 1024,dynamic=True)\n",
    "my_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "my_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "my_metrics = [metrics.Accuracy(),metrics.Precision(name='precision'),metrics.Recall(name='recall')]\n",
    "epochs = 400\n",
    "batch_size = 5\n",
    "\n",
    "model.compile(optimizer = my_optimizer, loss = my_loss, metrics = my_metrics)\n",
    "dynamic_result = model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=(vx,vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62711108",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = Model(inputs=model.input, outputs=model.output)\n",
    "new_input = model_copy.layers[1].output\n",
    "new_model = Model(inputs=new_input, outputs=model_copy.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2613195",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arrays = [[i, j, k] for i in range(2) for j in range(2) for k in range(2)][1:]\n",
    "for mask in mask_arrays:\n",
    "    evaluate(new_model,tx,ty,mask,print_stuff = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcd750c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.672297524 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "result = \"\"\"\n",
    "[0, 0, 1] 0.32 144 450\n",
    "[0, 1, 0] 0.3089 139 450\n",
    "[0, 1, 1] 0.3333 150 450\n",
    "[1, 0, 0] 0.3267 147 450\n",
    "[1, 0, 1] 0.3267 147 450\n",
    "[1, 1, 0] 0.3244 146 450\n",
    "[1, 1, 1] 0.3311 149 450\n",
    "\"\"\"\n",
    "print(get_flops(new_model, [tx[0:1],np.array([[1,1,1]])]),\"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(first_kernel = 64,first_flat = 1024,dynamic=False)\n",
    "my_optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "my_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "my_metrics = [metrics.Accuracy(),metrics.Precision(name='precision'),metrics.Recall(name='recall')]\n",
    "epochs = 300\n",
    "batch_size = 5\n",
    "\n",
    "model.compile(optimizer = my_optimizer, loss = my_loss, metrics = my_metrics)\n",
    "result = model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=(vx,vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee283b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = Model(inputs=model.input, outputs=model.output)\n",
    "new_input = model_copy.layers[1].output\n",
    "new_model = Model(inputs=new_input, outputs=model_copy.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cc62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,tx,ty,mask,print_stuff = \"\"):\n",
    "    sum_predict = 0\n",
    "    for i in range(len(tx)):\n",
    "        input_x = np.array([[[mask]]])*tx[i:i+1]\n",
    "        y_ = model(input_x,training = False)\n",
    "        if(np.argmax(y_[0]) == np.argmax(ty[i])):\n",
    "            sum_predict += 1\n",
    "    print(print_stuff,round(sum_predict/len(tx),4),sum_predict,len(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1170f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1] 0.0311 14 450\n",
      "[0, 1, 0] 0.0267 12 450\n",
      "[0, 1, 1] 0.1422 64 450\n",
      "[1, 0, 0] 0.0356 16 450\n",
      "[1, 0, 1] 0.0467 21 450\n",
      "[1, 1, 0] 0.0422 19 450\n",
      "[1, 1, 1] 0.42 189 450\n"
     ]
    }
   ],
   "source": [
    "mask_arrays = [[i, j, k] for i in range(2) for j in range(2) for k in range(2)][1:]\n",
    "for mask in mask_arrays:\n",
    "    evaluate(model,tx,ty,mask,print_stuff = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa49b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "3.671766294 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "result = \"\"\"\n",
    "[0, 0, 1] 0.0311 14 450\n",
    "[0, 1, 0] 0.0267 12 450\n",
    "[0, 1, 1] 0.1422 64 450\n",
    "[1, 0, 0] 0.0356 16 450\n",
    "[1, 0, 1] 0.0467 21 450\n",
    "[1, 1, 0] 0.0422 19 450\n",
    "[1, 1, 1] 0.42 189 450\n",
    "\"\"\"\n",
    "print(get_flops(model, [tx[0:1]]),\"GFLOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
