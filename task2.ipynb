{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db185b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python-headless\n",
    "!pip install torch\n",
    "!pip install Pillow\n",
    "!pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6baa7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Softmax,Input,MaxPooling2D,Dropout,Dense,Conv2D,Flatten,BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3b069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_y = len(os.listdir ('images'))\n",
    "def load_img(f):\n",
    "    f=open(f)\n",
    "    lines=f.readlines()\n",
    "    imgs, lab = [], []\n",
    "    for i in range(len(lines)):\n",
    "        fn, label = lines[i].split(' ')\n",
    "        \n",
    "        im1=cv2.imread(fn)\n",
    "        im1=cv2.resize(im1, (128,128))\n",
    "        imgs.append(im1)\n",
    "        lab.append(int(label))\n",
    "        \n",
    "    imgs= np.asarray(imgs, np.float32)\n",
    "    lab= np.asarray(lab, np.int32)\n",
    "    return imgs, np.eye(len_y)[lab],lab\n",
    "\n",
    "x,y,sim_y = load_img('train.txt')\n",
    "vx,vy,sim_vy = load_img('val.txt')\n",
    "tx,ty,sim_vy = load_img('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce94754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRDB(tf.keras.Model):\n",
    "    def __init__(self, K):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.fc1 = Conv2D(K, (3, 3), activation='relu', padding='same')\n",
    "        self.fc2 = Conv2D(K, (3, 3), activation='relu', padding='same')\n",
    "        self.fc3 = Conv2D(K, (3, 3), activation='relu', padding='same')\n",
    "        self.fcx = Conv2D(K, (1, 1), activation='relu', padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1 = self.fc1(x) + x\n",
    "        x2 = self.fc2(x1) + x1 + x\n",
    "        x3 = self.fc3(x2) + x2 + x1 + x\n",
    "        x4 = tf.concat([x, x1, x2, x3], -1)\n",
    "        x5 = self.fcx(x4)\n",
    "        x6 = x + x5\n",
    "        x6 = MaxPooling2D(pool_size=(4, 4))(x6)\n",
    "        return x6\n",
    "\n",
    "class RRDB_first(RRDB):\n",
    "    def __init__(self, K):\n",
    "        super(RRDB_first, self).__init__(K)\n",
    "        self.fc = Conv2D(K, (3, 3), activation='relu', padding='same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.fc(inputs)\n",
    "        x1 = self.fc1(x) + x\n",
    "        x2 = self.fc2(x1) + x1 + x\n",
    "        x3 = self.fc3(x2) + x2 + x1 + x\n",
    "        x4 = tf.concat([x, x1, x2, x3], -1)\n",
    "        x5 = self.fcx(x4)\n",
    "        x6 = x + x5\n",
    "        x6 = MaxPooling2D(pool_size=(4, 4))(x6)\n",
    "        return x6\n",
    "\n",
    "def net(first_kernel = 64,first_flat = 1024):\n",
    "    input_x = Input(shape=(128,128,3))\n",
    "    x = RRDB_first(first_kernel)(input_x)\n",
    "    x = RRDB(first_kernel)(x)\n",
    "    x = RRDB(first_kernel)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(first_flat, activation='relu')(x)\n",
    "    x = Dense(len_y)(x)\n",
    "    model = Model(inputs=input_x, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47bdee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model, model_inputs) -> float:\n",
    "        if not isinstance(\n",
    "            model, (tf.keras.models.Sequential, tf.keras.models.Model)\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Calculating FLOPS is only supported for \"\n",
    "                \"`tf.keras.Model` and `tf.keras.Sequential` instances.\"\n",
    "            )\n",
    "\n",
    "        from tensorflow.python.framework.convert_to_constants import (\n",
    "            convert_variables_to_constants_v2_as_graph,\n",
    "        )\n",
    "\n",
    "        # Compute FLOPs for one sample\n",
    "        batch_size = 1\n",
    "        inputs = [\n",
    "            tf.TensorSpec([batch_size] + list(inp.shape[1:]), inp.dtype)\n",
    "            for inp in model_inputs\n",
    "        ]\n",
    "\n",
    "        # convert tf.keras model into frozen graph to count FLOPs about operations used at inference\n",
    "        real_model = tf.function(model).get_concrete_function(inputs)\n",
    "        frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\n",
    "\n",
    "        # Calculate FLOPs with tf.profiler\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = (\n",
    "            tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                tf.compat.v1.profiler.ProfileOptionBuilder().float_operation()\n",
    "            )\n",
    "            .with_empty_output()\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=frozen_func.graph, run_meta=run_meta, cmd=\"scope\", options=opts\n",
    "        )\n",
    "\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "        # convert to GFLOPs\n",
    "        return (flops.total_float_ops / 1e9)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fccf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(first_kernel = 512,first_flat = 2048)\n",
    "my_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "my_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "my_metrics = [metrics.Accuracy(),metrics.Precision(name='precision'),metrics.Recall(name='recall')]\n",
    "epochs = 30\n",
    "batch_size = 5\n",
    "\n",
    "model.compile(optimizer = my_optimizer, loss = my_loss, metrics = my_metrics)\n",
    "dynamic_result = model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_data=(vx,vy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca6150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142.242927641"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flops(model, [tx[0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7024f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.4556 205 450\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model,tx,ty,print_stuff = \"\"):\n",
    "    sum_predict = 0\n",
    "    for i in range(len(tx)):\n",
    "        input_x = tx[i:i+1]\n",
    "        y_ = model(input_x)\n",
    "        if(np.argmax(y_[0]) == np.argmax(ty[i])):\n",
    "            sum_predict += 1\n",
    "    print(print_stuff,round(sum_predict/len(tx),4),sum_predict,len(tx))\n",
    "evaluate(model,tx,ty,print_stuff = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e121dc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fintechuser/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "pre_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=False)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pre_model.parameters(),lr=0.0001)\n",
    "epochs = 30\n",
    "class random_seed_class():\n",
    "    random_seed_int = 0\n",
    "    def __init__(self):\n",
    "        random_seed_int = random.seed(620)\n",
    "        self.update_seed()\n",
    "    def update_seed(self):\n",
    "        self.random_seed_int = random.randint(1, 10000)\n",
    "    def shuffle(self,*args,update = False):\n",
    "        for arg in args:\n",
    "            np.random.seed(self.random_seed_int)\n",
    "            np.random.shuffle(arg)\n",
    "        if(update):\n",
    "            self.update_seed()\n",
    "def custom_fit(model, X, Y, num_epochs):\n",
    "    Dealer = random_seed_class()\n",
    "    for epoch in range(num_epochs):\n",
    "        Dealer.shuffle(X,Y,update = True)\n",
    "        for i in range(int(len(X)/5)):\n",
    "            inputs = torch.from_numpy(np.swapaxes(x[i:i+5], 1, 3))\n",
    "            targets = torch.from_numpy((Y[i:i+5])).to(torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(i%1000==0):\n",
    "                print(f\"Epoch [{epoch+1} {i*5 + 5}sample\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "custom_fit(pre_model,x,sim_y,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c41b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0 0 450\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model,tx,ty,print_stuff = \"\"):\n",
    "    sum_predict = 0\n",
    "    for i in range(len(tx)):\n",
    "        input_x = torch.from_numpy(np.swapaxes(tx[i:i+1], 1, 3))\n",
    "        y_ = model(input_x)\n",
    "        if(np.argmax(y_[0].detach().numpy()) == np.argmax(ty[i])):\n",
    "            sum_predict += 1\n",
    "    print(print_stuff,round(sum_predict/len(tx),4),sum_predict,len(tx))\n",
    "evaluate(pre_model,tx,ty,print_stuff = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0398341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21797672"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in pre_model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e64ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummaryX import summary\n",
    "summary(pre_model,torch.from_numpy(np.swapaxes(tx[0:1], 1, 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
